<!DOCTYPE html>
<html lang="en-us">
    <head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
	
		<title>
				Meet molecules, wearing your avatar (English) &middot; -kTlogP
		</title>
	
		
  		<link rel="stylesheet" href="/minus_kTlogP/css/style.css">
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
	
		
		<link rel="icon" type="image/png" sizes="32x32" href="/minus_kTlogP/images/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="/minus_kTlogP/images/favicon-16x16.png">
		<link rel="apple-touch-icon" sizes="180x180" href="/minus_kTlogP/images/apple-touch-icon.png">
	
		
		<link href="" rel="alternate" type="application/rss+xml" title="-kTlogP" />
	</head>
	
    <body>
        		<nav class="nav">
			<div class="nav-container">
				<a href="/minus_kTlogP/">
					<h2 class="nav-title">-kTlogP</h2>
				</a>
				<ul>
    <li><a href="/minus_kTlogP/about">About</a></li>
    <li><a href="/minus_kTlogP/">Posts</a></li>
</ul>
			</div>
		</nav>

        

<main>
	<div class="post">
		<div class="post-info">
    <span>Written by</span>
        Koya.S
        <br>
        <span>on&nbsp;</span><time datetime="2019-02-23 06:04:39 &#43;0900 JST">February 23, 2019</time>
</div>
		<h1 class="post-title">Meet molecules, wearing your avatar (English)</h1>
<div class="post-line"></div>

		

		<p>I tried to make third person perspective videos of my avatar handling molecules.</p>

<p>This is English version of <a href="http://yakomaxa.github.io/minus_kTlogP/post/nanomevmcliv_ja/">http://yakomaxa.github.io/minus_kTlogP/post/nanomevmcliv_ja/</a></p>

<h1 id="purpose">Purpose</h1>

<p>Let an avatar look like handling molecular models.</p>

<h1 id="result">Result</h1>

<iframe width="808" height="606" src="https://www.youtube.com/embed/2x_ex2RpHX8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h1 id="method">Method</h1>

<ul>
<li>View molecules with a VR molecular viewer such as Nanome.</li>
<li>Act as the avatar using Virtual Motion Capture.</li>
<li>Synthesize these two by LIV.</li>
</ul>

<h1 id="advantages">Advantages</h1>

<ul>
<li>With the player-image synthesized with molecules, explanations on molecules would become more attractive and intuitive than using 2D molecular viewers.</li>
<li>Avatar-based MR-synthesis is cheaper and easier than real-camera chroma-key synthesis.</li>
<li>Wearing avatar allows the “resolution” of the player-images to fit with molecule models.</li>
</ul>

<h1 id="problems-unsolved">Problems unsolved</h1>

<p>Currently, some molecular models cannot be image-synthesized in this way, which is a known behavior of the molecular viewer.</p>

<h1 id="perspectives">Perspectives</h1>

<p>I’d like to use this kind of system to make presentations or explanations about molecular structures.</p>

<h1 id="conclusion">Conclusion</h1>

<ul>
<li>Nanome + VMC + LIV partially realizes what I want to do.</li>
<li>Since the combination is not perfect, I’m seeking for alternatives.</li>
</ul>

<h1 id="q-a">Q&amp;A</h1>

<p>Q1. Which VR molecule viewers have you tested?</p>

<ul>
<li>Nanome is the best as of now because it’s a native VR molecular viewer. Probably, it’s the only native VR molecule viewer currently available.</li>
<li>Chimera-X has the VR mode and shows cool models. However, controllability is not so good so of now compared to the non-VR mode. As is discussed in the original paper.</li>
<li>Pymol seems to have some VR function but I’ve not tried</li>
<li>I tested some other seemingly-VR-viewers developed by individual researchers, but unfortunately they did not work well in my environment and for my purpose.</li>
</ul>

<p>Q2. What VR-instruments are you using?</p>

<ul>
<li>I use Oculus Rift for HMD and Touch for controllers.</li>
</ul>

<p>Q3. How was this avatar made and used?</p>

<ul>
<li>I used VRoid Studio to compose the avatar, which can export a specific type (.vrm) of humanoid models.</li>
<li>To playact as the avatar, I used Virtual Motion Capture.</li>
</ul>

<h1 id="references">References</h1>

<h2 id="softwares">Softwares</h2>

<ul>
<li>Nanome is a native VR molecular viewer.

<ul>
<li><a href="https://nanome.ai/nanome/">https://nanome.ai/nanome/</a></li>
</ul></li>
<li>Virtual Motion Capture is software to make virtual camera images for avatar-based MR-synthesis.

<ul>
<li><a href="https://sh-akira.github.io/VirtualMotionCapture/about.html">https://sh-akira.github.io/VirtualMotionCapture/about.html</a></li>
</ul></li>
<li>LIV is software for chroma-key based MR-synthesis.

<ul>
<li><a href="https://liv.tv/">https://liv.tv/</a></li>
</ul></li>
<li>VRoidStudio is software to compose a VRM-formatted humanoid model.

<ul>
<li><a href="https://studio.vroid.com/">https://studio.vroid.com/</a></li>
</ul></li>
</ul>

<h2 id="previous-study">Previous study</h2>

<ul>
<li>How to bring molecular models into MMD (A Japanese blog post).

<ul>
<li>MikuMikuDance に分子構造データを持ち込む方法</li>
<li><a href="http://d.hatena.ne.jp/biochem_fan/20110829/1314627892">http://d.hatena.ne.jp/biochem_fan/20110829/1314627892</a></li>
<li>I remember I read this when I was an undergraduate student.</li>
</ul></li>
</ul>

<h2 id="papers">Papers</h2>

<ul>
<li>Molecular Visualization on the Holodeck

<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S002228361830696X">https://www.sciencedirect.com/science/article/pii/S002228361830696X</a></li>
</ul></li>
</ul>

		
	</div>

	<div class="pagination">
		<a href="/minus_kTlogP/post/vrmolviewers_ja/" class="left arrow">&#8592;</a>

		<a href="#" class="top">Top</a>
	</div>
</main>


        		<footer>
			<span>
			&copy; <time datetime="2019-02-23 23:36:29.12352 &#43;0900 JST m=&#43;0.692389196">2019</time> Koya Sakuma. Made with <a href='https://gohugo.io'>Hugo</a> using the <a href='https://github.com/EmielH/tale-hugo/'>Tale</a> theme.
			</span>
		</footer>

    </body>
</html>
