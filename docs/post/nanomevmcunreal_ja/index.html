<!DOCTYPE html>
<html lang="en-us">
    <head>
               
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-135009439-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
 
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
			<meta name="description" content="OculusのソフトでVMCを使う試み">

		<meta property="og:title" content="分子受肉の続き(Oculus版)" /> 
		<meta property="og:type" content="blog" />
		<meta property="og:description" content="OculusのソフトでVMCを使う試み" /> 
		<meta property="og:url" content="/minus_kTlogP/post/nanomevmcunreal_ja/" /> 
		<meta property="og:site_name" content="Sakuma -kTlogP" />
		<meta property="og:image" content="../../img/VMCOculusNanome.png" />
			
		<title>
				分子受肉の続き(Oculus版) &middot; Sakuma -kTlogP
		</title>
	
		
  		<link rel="stylesheet" href="/minus_kTlogP/css/style.css">
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
	
		
		<link rel="icon" type="image/png" sizes="32x32" href="/minus_kTlogP/images/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="/minus_kTlogP/images/favicon-16x16.png">
		<link rel="apple-touch-icon" sizes="180x180" href="/minus_kTlogP/images/apple-touch-icon.png">
	
		
		<link href="" rel="alternate" type="application/rss+xml" title="Sakuma -kTlogP" />
	</head>
	

    <body>
        		<nav class="nav">
			<div class="nav-container">
				<a href="/minus_kTlogP/">
					<h2 class="nav-title">Sakuma -kTlogP</h2>
				</a>
				<ul>
    <li><a href="/minus_kTlogP/about">About</a></li>
    <li><a href="/minus_kTlogP/">Posts</a></li>
</ul>
			</div>
		</nav>

        

<main>
	<div class="post">
		<div class="post-info">
    <span>Written by</span>
        Koya.S
        <br>
        <span>on&nbsp;</span><time datetime="2019-02-26 22:18:15 &#43;0900 JST">February 26, 2019</time>
</div>
		<h1 class="post-title">分子受肉の続き(Oculus版)</h1>
<div class="post-line"></div>

		

		<p>要約</p>

<p>やりたいことがOculus版のソフトだとうまくいく。なので「Oculus版のMR機能+バーチャルモーションキャプチャー」の方法を模索する。結果的に、だいたい動いた。まだカメラのキャリブレーションが難しいのでどうにかしたい。</p>

<p><a href="https://yakomaxa.github.io/minus_kTlogP/post/nanomevmcliv_ja/">分子に会うため受肉した話</a>の続きです。</p>

<p>この記事は、いまのところ文字しかありませんよ。</p>

<h1 id="一部の分子モデルが正しく画像合成されない問題">一部の分子モデルが正しく画像合成されない問題</h1>

<p>前回、Nanome + VMC + LIVの組み合わせでかなりやれることがわかった。しかし、クロマキー合成すると、特定のモデルが常にアバターの裏側に行ってしまう問題が残っていた。前回はその辺をごまかすために、surface表示にしてから体の前に持ってくることでごまかしていたのだけど、これだと実用上問題がある。直したい。</p>

<h1 id="仕様らしい">仕様らしい</h1>

<p>色々試してみて、４分割画面の時点でalpha maskが正常に表示されないことを確認したので、ビューアソフト内部の問題だと判断した。開発企業に問い合わせて、そういう挙動になることは既知、という答えをいただいだ。とても詳しく回答いただいて、非常にありがたかった。もはや打つ手がない感じで、ちょっと残念だ、というのが前回までの話（書いてないけど）。</p>

<h1 id="oculus版の存在を思い出す">Oculus版の存在を思い出す</h1>

<p>ほぼ諦めかけていたのだが、偶然、このまとめを目にした。</p>

<p><a href="https://twitter.com/i/moments/1098106642812395520?ref_src=twsrc%5Etfw">Oculus Rift+バーチャルモーションキャプチャー+LIVでMR合成する方法</a></p>

<p>とても参考になった。</p>

<p>「Oculus APIだとLIVをつかったMRSはできない」というところを読んだ時、そういえばOculus版もあっことを思い出した。そういえばOculus版の方にはMixed Reality Captureという機能があった気がしたので、その動かし方を調べたら公式で説明されていた。<a href="https://developer.oculus.com/documentation/unity/latest/concepts/unity-mrc/">ここのサイト</a>。</p>

<p>関係ないが、このOculusのサイト（とくにMRC周辺・・・）、リンクが切れていがちで精神的に翻弄されやすい。たぶん日本語版のページがないのだろう。記事の中のリンクではなく、左のタブにあるリンクでひらけば大丈夫。</p>

<h1 id="なぜかoculus版だとうまくいく">なぜかOculus版だとうまくいく</h1>

<p>まず、コマンドラインから目的のソフトを以下のオプション付きで起動して、二画面分割が出ることを確認。</p>

<ul>
<li>-mixedreality -externalcomposition</li>
</ul>

<p>この時点で、クロマキーのfront/backの認識がうまく働いていることが確認できたので、さらに進めることにした。</p>

<p>以下のオプション付きで起動して、LIVのcompositorと同じような画面が出ることを確認（Unityがまだシグナルを送ってません、的なガビガビの文字）。</p>

<ul>
<li>-mixedreality -directcomposition</li>
</ul>

<p>さらにVMCを起動し仮想カメラをONにした状態で、directcompositionで起動し、画面サイズと背景色を合わせるとクロマキー合成ができる。</p>

<p>これで、システム的にはOculus版でもVMCを使ったクロマキーができるようになった。</p>

<p>やっとできた！・・・のだけど、まだ問題が残っている。</p>

<h1 id="カメラキャリブレーション">カメラキャリブレーション</h1>

<p>カメラキャリブレーションが難所だった（いまだに完全には解決してない）</p>

<ul>
<li>Oculusの公式で書いてあるとおり、CameraTool.exeを動かす

<ul>
<li>sl_zed64.dllとsl_core64.dllがないと言われたので、ZED SDKを入れたら動くようになった。ただし、ZED SDKを入れる段階でCUDAの更新とか色々行われたので、何が効いたのかいまいちわからない。CUDAの更新とかちょっと嫌な思い出しかないので、あまりやりたくない。</li>
</ul></li>
<li>CameraToolを起動する

<ul>
<li>CameraToolでVMCの仮想カメラは認識されるが、選択しても使うことができない。pidが不明です的なことを言われたと思う。</li>
<li>なので、まずは本物のカメラを使って適当にキャリブレーションする。</li>
<li>最後までやってファイルを保存すると、cameracalibration.xmlが保存される</li>
</ul></li>
<li>cameracalibration.xmlの中身を適当に改変する。

<ul>
<li>形式はxmlで可読だったので、手で書いてみることにした。</li>
<li>CameraToolはOpenCVのカメラキャリブレーションを使っているらしく、そのあたりののドキュメントを読みながら適当に数値を入れ直す。</li>
<li>translation rotation cameramatrix これらを書きかえる</li>
<li>distorsion補正は0でいいと思う（わからない）</li>
</ul></li>
</ul>

<h1 id="本番">本番</h1>

<ul>
<li>VMCを起動し、設定して、キャリブレーション。</li>
<li>externalcamera.cfgを出力し、cameracalibration.xmlに変換。</li>
<li>CameraToolを起動して、cameracalibration.xmlを読み込んでSend to Oculus Serverする。

<ul>
<li>もしVMC仮想カメラ以外にカメラを繋いでない場合は、CameraToolを終了する（こちらで仮想カメラを呼んでるとゲームから呼べないらしい）。</li>
</ul></li>
<li>目的のゲームを-mixedreality -directcompositionで起動する。</li>
</ul>

<h1 id="わかったことまとめ">わかったことまとめ</h1>

<p>externalcamera.cfgに相当する情報が、二つのファイルに分かれている。</p>

<ul>
<li>mrc.confg

<ul>
<li>-create_mrc_config のオプション付きで起動すると、実行ファイルと同階層にあるDataフォルダの中に置かれる。</li>
<li>-load_mrc_config で、そのファイルを読める。</li>
<li>一度起動して出力されたファイルを編集し、-load_mrc_config付きで再び起動すると反映される。</li>
<li>このファイルにはカメラ位置や回転を指定する変数がない。</li>
<li>ゲームのバイナリが読む。</li>
</ul></li>
</ul>

<p>参考：OculusのBeatSabarでMR合成を頑張ろうとした先人のレポジトリ</p>

<p><a href="https://github.com/zipleen/BSOculusMREnabler/blob/master/README.md">https://github.com/zipleen/BSOculusMREnabler/blob/master/README.md</a></p>

<ul>
<li>cameracalibration.xml

<ul>
<li>座標・回転・歪み補正・カメラ行列の情報などが書かれている。</li>
<li>CameraToolで読んで、Oculus Sever経由でゲームに渡す。</li>
</ul></li>
</ul>

<h1 id="次やりたいこと">次やりたいこと</h1>

<ul>
<li>externalcamera.cfgを読んでcameracalibration.xmlを吐くスクリプトを書く

<ul>
<li>まだいまいち両者の数値の対応関係がよくわかってないので、しばらくかかりそう。</li>
<li>FOVのあたり（たぶんCameraMatrixの値から出てくる）は三角形かいて計算しないといけないような気がしている。</li>
<li>rotationの４変数が何なのか理解できてない。Yaw Pitch Rollを２つの面の回転で表現してる？</li>
</ul></li>
<li>LIVみたいに合成した映像をHMDへ返す方法はないだろうか・・・。</li>
</ul>

		
	</div>

	<div class="pagination">
		<a href="/minus_kTlogP/post/nanomevmcliv_en/" class="left arrow">&#8592;</a>

		<a href="#" class="top">Top</a>
	</div>
</main>


        		<footer>
			<span>
			&copy; <time datetime="2019-02-28 08:26:19.783377 &#43;0900 JST m=&#43;0.122803654">2019</time> Koya Sakuma. Made with <a href='https://gohugo.io'>Hugo</a> using the <a href='https://github.com/EmielH/tale-hugo/'>Tale</a> theme.
			</span>
		</footer>

    </body>
</html>
